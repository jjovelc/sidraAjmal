{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPhkeqjUwPp0diI9d6laYXR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["! pip install numpy\n","! pip install scipy\n","! pip install pandas\n","! pip install matplotlib\n","! pip install scikit-learn\n","! pip install openpyxl"],"metadata":{"collapsed":true,"id":"9mHS0zv-PPVf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742558641730,"user_tz":360,"elapsed":42697,"user":{"displayName":"Juan Jovel","userId":"16121091103107305276"}},"outputId":"968e8a84-4529-412d-dfb4-f2d09f041559"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.14.1)\n","Requirement already satisfied: numpy<2.3,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy) (2.0.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from scipy.signal import savgol_filter\n","import matplotlib.pyplot as plt\n","from sklearn.ensemble import IsolationForest\n","import os\n","from openpyxl import load_workbook"],"metadata":{"id":"f6-MMHnMPNOD","executionInfo":{"status":"ok","timestamp":1742558656498,"user_tz":360,"elapsed":6121,"user":{"displayName":"Juan Jovel","userId":"16121091103107305276"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h4NQzPD-KlYr","executionInfo":{"status":"ok","timestamp":1742559041486,"user_tz":360,"elapsed":45146,"user":{"displayName":"Juan Jovel","userId":"16121091103107305276"}},"outputId":"98ec3172-a108-495f-9f69-664c797b2f9d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["os.chdir('/content/drive/My Drive/jj/projects/2025/sidraAjmal/data')\n","! ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qzsut3dfLnfB","executionInfo":{"status":"ok","timestamp":1742559045402,"user_tz":360,"elapsed":786,"user":{"displayName":"Juan Jovel","userId":"16121091103107305276"}},"outputId":"2ecd9c3c-7f04-4340-92be-114b5aeaa033"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["example_with_positive_cases_edited.xlsx   fluorescence_results_20250321_040344\n","fluorescence_results_20250320_211046\t  fluorescence_results_20250321_040344.txt\n","fluorescence_results_20250320_211046.txt  low_TXA_conc_modified.xlsx\n","fluorescence_results_20250320_231331\t  low_TXA_conc.xlsx\n","fluorescence_results_20250320_231331.txt\n"]}]},{"cell_type":"code","source":["def detect_peaks_comprehensive(data, window_size=5, min_prominence=0.08, smoothed=None):\n","    \"\"\"\n","    Comprehensive peak detection algorithm for fluorescence data\n","\n","    Parameters:\n","    -----------\n","    data : list or array\n","        The fluorescence intensity data\n","    window_size : int\n","        Size of the window to check for local maxima\n","    min_prominence : float\n","        Minimum relative prominence required (as a fraction of data range)\n","    smoothed : array, optional\n","        Pre-computed smoothed data (if available)\n","\n","    Returns:\n","    --------\n","    peaks : list\n","        Indices of detected peaks\n","    smoothed : array\n","        Smoothed data (if provided or calculated)\n","    peak_info : list\n","        Detailed information about each peak\n","    \"\"\"\n","    import numpy as np\n","    from scipy.signal import savgol_filter, find_peaks\n","\n","    # Apply smoothing if not already provided\n","    if smoothed is None:\n","        # Ensure window size is odd and not larger than the data\n","        if len(data) < window_size * 2:\n","            window_size = max(3, len(data) // 2)\n","            if window_size % 2 == 0:\n","                window_size -= 1\n","\n","        poly_order = min(2, window_size - 1)\n","        smoothed = savgol_filter(data, window_length=window_size, polyorder=poly_order)\n","\n","    # Calculate residuals (difference between actual and smoothed)\n","    residuals = np.array(data) - smoothed\n","\n","    # Method 1: Direct peak finding using scipy's find_peaks (works well for clear peaks)\n","    data_range = np.max(data) - np.min(data)\n","    height_threshold = np.min(data) + (data_range * 0.05)  # 5% above minimum\n","    distance = max(2, len(data) // 20)  # At least 2, or 1/20th of the data length\n","\n","    # Find peaks with scipy's algorithm\n","    peaks_scipy, properties = find_peaks(\n","        data,\n","        height=height_threshold,\n","        distance=distance,\n","        prominence=(data_range * min_prominence)\n","    )\n","\n","    # Method 2: Find peaks based on local maxima with prominence calculation\n","    half_window = window_size // 2\n","    local_maxima = []\n","\n","    # Find all local maxima\n","    for i in range(half_window, len(data) - half_window):\n","        window = data[i - half_window:i + half_window + 1]\n","        if data[i] == max(window):\n","            # Calculate prominence\n","            # Look backward for either a higher point or the lowest point before a higher one\n","            left_min = data[i]\n","            for j in range(i - 1, -1, -1):\n","                if data[j] > data[i]:\n","                    break\n","                left_min = min(left_min, data[j])\n","\n","            # Look forward for either a higher point or the lowest point before a higher one\n","            right_min = data[i]\n","            for j in range(i + 1, len(data)):\n","                if data[j] > data[i]:\n","                    break\n","                right_min = min(right_min, data[j])\n","\n","            baseline = max(left_min, right_min)\n","            prominence = data[i] - baseline\n","            rel_prominence = prominence / data_range\n","\n","            # Add to list if it meets prominence threshold\n","            if rel_prominence >= min_prominence:\n","                local_maxima.append({\n","                    'index': i,\n","                    'value': data[i],\n","                    'prominence': prominence,\n","                    'rel_prominence': rel_prominence\n","                })\n","\n","    # Combine both methods and remove duplicates\n","    peaks_from_local = [p['index'] for p in local_maxima]\n","    all_peaks = list(set(list(peaks_scipy) + peaks_from_local))\n","    all_peaks.sort()\n","\n","    # Deduplicate peaks that are very close to each other\n","    if len(all_peaks) > 1:\n","        filtered_peaks = [all_peaks[0]]\n","        for i in range(1, len(all_peaks)):\n","            if all_peaks[i] - filtered_peaks[-1] > distance:\n","                filtered_peaks.append(all_peaks[i])\n","        all_peaks = filtered_peaks\n","\n","    # Generate detailed info for each peak\n","    peak_info = []\n","    for peak_idx in all_peaks:\n","        # Re-calculate prominence for all final peaks\n","        left_min = data[peak_idx]\n","        for j in range(peak_idx - 1, -1, -1):\n","            if data[j] > data[peak_idx]:\n","                break\n","            left_min = min(left_min, data[j])\n","\n","        right_min = data[peak_idx]\n","        for j in range(peak_idx + 1, len(data)):\n","            if data[j] > data[peak_idx]:\n","                break\n","            right_min = min(right_min, data[j])\n","\n","        baseline = max(left_min, right_min)\n","        prominence = data[peak_idx] - baseline\n","        rel_prominence = prominence / data_range\n","        height_above_smoothed = data[peak_idx] - smoothed[peak_idx]\n","\n","        peak_info.append({\n","            'index': peak_idx,\n","            'value': data[peak_idx],\n","            'prominence': prominence,\n","            'rel_prominence': rel_prominence,\n","            'height_above_smoothed': height_above_smoothed\n","        })\n","\n","    return all_peaks, smoothed, peak_info\n","\n","\n","def process_excel_file_comprehensive(file_path, output_dir=None, debug_mode=True,\n","                                  window_size=5, min_prominence=0.08):\n","    \"\"\"\n","    Process Excel file with fluorescence data using comprehensive peak detection\n","\n","    Parameters:\n","    -----------\n","    file_path : str\n","        Path to the Excel file\n","    output_dir : str\n","        Directory to save results, default is fluorescence_results_YYYYMMDD_HHMMSS\n","    debug_mode : bool\n","        If True, save plots for all analyzed pairs\n","    window_size : int\n","        Size of the window to check for local maxima (should be odd)\n","    min_prominence : float\n","        Minimum relative prominence required (as a fraction of data range)\n","    \"\"\"\n","    import os\n","    import pandas as pd\n","    import numpy as np\n","    import matplotlib.pyplot as plt\n","    from openpyxl import load_workbook\n","    from scipy.signal import savgol_filter\n","    import datetime\n","    import sys\n","\n","    # Create a timestamp for the output directory if not provided\n","    if output_dir is None:\n","        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","        output_dir = f\"fluorescence_results_{timestamp}\"\n","\n","    # Create output directory\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # Set up logging to file with the same name as the directory\n","    log_file = f\"{output_dir}.txt\"\n","    original_stdout = sys.stdout\n","    log_handle = open(log_file, 'w')\n","    sys.stdout = log_handle\n","\n","    # Load the workbook\n","    print(f\"Loading workbook: {file_path}\")\n","    wb = load_workbook(file_path, data_only=True)\n","\n","    results_summary = []\n","\n","    # Process each sheet\n","    print(f\"COMPREHENSIVE PEAK DETECTION: Using window_size={window_size}, min_prominence={min_prominence}\")\n","    print(f\"Available sheets: {wb.sheetnames}\")\n","\n","    for sheet_name in wb.sheetnames:\n","        print(f\"\\nProcessing sheet: {sheet_name}\")\n","        sheet = wb[sheet_name]\n","\n","        # Get basic sheet dimensions\n","        max_row = sheet.max_row\n","        max_col = sheet.max_column\n","        print(f\"Sheet has {max_row} rows and {max_col} columns\")\n","\n","        # First, check if this is a data sheet by looking for \"Site\" in cell B1\n","        if sheet['B1'].value != 'Site':\n","            print(f\"Skipping {sheet_name} - doesn't match expected format\")\n","            continue\n","\n","        # Fix headers: Move headers starting at C1 two cells to the right\n","        max_col = sheet.max_column\n","        for col in range(max_col, 2, -1):\n","            if col >= 5:  # Only move columns C, D, E... (3, 4, 5...)\n","                header_value = sheet.cell(row=1, column=col-2).value\n","                sheet.cell(row=1, column=col).value = header_value\n","\n","        # Clear the old header positions\n","        sheet.cell(row=1, column=3).value = None\n","        sheet.cell(row=1, column=4).value = None\n","\n","        # Process data in groups of three rows\n","        row = 2  # Start at row 2\n","        max_row = sheet.max_row\n","\n","        while row <= max_row - 2:  # Ensure we have at least 3 rows to process\n","            # Check if we have a Cy5-Cy5-Cy3 pattern\n","            cell_b1 = sheet.cell(row=row, column=2).value\n","            cell_b2 = sheet.cell(row=row+1, column=2).value\n","            cell_b3 = sheet.cell(row=row+2, column=2).value\n","\n","        if cell_b1 == \"Cy5\" and cell_b2 == \"Cy5\" and cell_b3 == \"Cy3\":\n","                # Use the second Cy5 row as mentioned in the requirements\n","                cy5_row = row + 1\n","                cy3_row = row + 2\n","\n","        # Extract data for Cy5 (skip the first 4 columns: A, B, C, D)\n","        cy5_data = []\n","        for col in range(5, max_col + 1):\n","          value = sheet.cell(row=cy5_row, column=col).value\n","          if isinstance(value, (int, float)):\n","            cy5_data.append(value)\n","\n","        # Extract data for Cy3\n","        cy3_data = []\n","        for col in range(5, max_col + 1):\n","          value = sheet.cell(row=cy3_row, column=col).value\n","          if isinstance(value, (int, float)):\n","            cy5_data.append(value)\n","\n","\n","        # Make sure we have data\n","        if len(cy5_data) > 0 and len(cy3_data) > 0:\n","            # Get site information\n","            site_id = sheet.cell(row=cy5_row, column=1).value\n","            site_number = sheet.cell(row=cy5_row, column=2).value\n","\n","            # Use our comprehensive peak detection function\n","            cy5_peaks, cy5_smoothed, cy5_peak_info = detect_peaks_comprehensive(\n","                cy5_data, window_size=window_size, min_prominence=min_prominence\n","            )\n","            cy3_peaks, cy3_smoothed, cy3_peak_info = detect_peaks_comprehensive(\n","                cy3_data, window_size=window_size, min_prominence=min_prominence\n","            )\n","\n","            # Check if this is a positive match (Cy5 has peaks, Cy3 doesn't)\n","            match_found = (len(cy5_peaks) > 0 and len(cy3_peaks) == 0)\n","\n","            # Log detailed peak information for debugging\n","            if match_found or debug_mode:\n","                print(f\"Row {cy5_row}: Found {len(cy5_peaks)} peaks\")\n","                for i, peak_info in enumerate(cy5_peak_info):\n","                    print(f\"  Peak {i+1}: Position {peak_info['index']+1}, \"\n","                          f\"Value {peak_info['value']:.2f}, \"\n","                          f\"Prominence {peak_info['prominence']:.2f} \"\n","                          f\"({peak_info['rel_prominence']*100:.2f}%)\")\n","\n","                print(f\"Row {cy3_row}: Found {len(cy3_peaks)} peaks\")\n","                for i, peak_info in enumerate(cy3_peak_info):\n","                    print(f\"  Peak {i+1}: Position {peak_info['index']+1}, \"\n","                          f\"Value {peak_info['value']:.2f}, \"\n","                          f\"Prominence {peak_info['prominence']:.2f} \"\n","                          f\"({peak_info['rel_prominence']*100:.2f}%)\")\n","\n","            if match_found:\n","                valid_groups += 1\n","                print(f\"THIS IS A POSITIVE MATCH! Cy5 has {len(cy5_peaks)} peaks, Cy3 has none.\")\n","            elif debug_mode:\n","                print(f\"Not a match - {'Cy5 has no peaks' if len(cy5_peaks) == 0 else 'Cy3 has peaks too'}\")\n","\n","            # Check whether to visualize this data pair\n","            should_visualize = match_found  # Always visualize positive matches\n","            if debug_mode:                  # In debug mode, visualize all pairs\n","                should_visualize = True\n","\n","            if should_visualize:\n","                # Create visualization\n","                fig, axs = plt.subplots(2, 1, figsize=(12, 10))\n","\n","                # Plot Cy5 data\n","                axs[0].plot(cy5_data, 'g-', label=f'Cy5 Data (Row {cy5_row})')\n","                axs[0].plot(cy5_smoothed, 'r--', alpha=0.7, label='Smoothed Trend')\n","                if cy5_peaks:\n","                    axs[0].scatter([p for p in cy5_peaks], [cy5_data[i] for i in cy5_peaks],\n","                                color='green', marker='o', s=100, label='Detected Peaks')\n","\n","                    # Annotate peaks with their position and prominence\n","                    for i, peak_idx in enumerate(cy5_peaks):\n","                        info = next(info for info in cy5_peak_info if info['index'] == peak_idx)\n","                        axs[0].annotate(f\"P{i+1}: {peak_idx+1}\",\n","                                      xy=(peak_idx, cy5_data[peak_idx]),\n","                                      xytext=(0, 10),\n","                                      textcoords='offset points',\n","                                      fontsize=9)\n","\n","                axs[0].set_title(f'Sheet: {sheet_name}, Cy5 Fluorescence (Row {cy5_row})')\n","                axs[0].legend()\n","                axs[0].grid(True)\n","\n","                # Plot Cy3 data\n","                axs[1].plot(cy3_data, 'b-', label=f'Cy3 Data (Row {cy3_row})')\n","                axs[1].plot(cy3_smoothed, 'r--', alpha=0.7, label='Smoothed Trend')\n","                if cy3_peaks:\n","                    axs[1].scatter([p for p in cy3_peaks], [cy3_data[i] for i in cy3_peaks],\n","                                color='red', marker='o', s=100, label='Detected Peaks')\n","\n","                    # Annotate peaks with their position and prominence\n","                    for i, peak_idx in enumerate(cy3_peaks):\n","                        info = next(info for info in cy3_peak_info if info['index'] == peak_idx)\n","                        axs[1].annotate(f\"P{i+1}: {peak_idx+1}\",\n","                                      xy=(peak_idx, cy3_data[peak_idx]),\n","                                      xytext=(0, 10),\n","                                      textcoords='offset points',\n","                                      fontsize=9)\n","\n","                axs[1].set_title(f'Cy3 Fluorescence (Row {cy3_row})')\n","                axs[1].legend()\n","                axs[1].grid(True)\n","\n","                # Add detailed analysis information if in debug mode\n","                if debug_mode:\n","                    fig.set_size_inches(12, 15)\n","                    plt.subplots_adjust(hspace=0.4)\n","\n","                    # Add more detailed text about the peaks\n","                    fig.text(0.1, 0.01,\n","                            f\"Cy5 Peaks: {len(cy5_peaks)}\\n\" +\n","                            \"\\n\".join([f\"Peak at {p+1}: Value={cy5_data[p]:.1f}, \" +\n","                                      f\"Prominence={next(i['prominence'] for i in cy5_peak_info if i['index'] == p):.1f} \" +\n","                                      f\"({next(i['rel_prominence']*100 for i in cy5_peak_info if i['index'] == p):.1f}%)\"\n","                                      for p in cy5_peaks]),\n","                            fontsize=9, verticalalignment='bottom')\n","\n","                plt.tight_layout()\n","\n","                # Add debug indicator to filename if not a positive match\n","                if match_found:\n","                    plot_filename = f\"{output_dir}/{sheet_name}_Rows{cy5_row}-{cy3_row}.png\"\n","                else:\n","                    plot_filename = f\"{output_dir}/DEBUG_{sheet_name}_Rows{cy5_row}-{cy3_row}.png\"\n","\n","                plt.savefig(plot_filename)\n","                plt.close(fig)\n","\n","                # Add to results summary if it's a positive match\n","                if match_found:\n","                    # Format peak information for the summary\n","                    peak_positions = [p+1 for p in cy5_peaks]\n","                    peak_heights = [info['height_above_smoothed'] for info in cy5_peak_info]\n","                    peak_prominences = [info['prominence'] for info in cy5_peak_info]\n","                    relative_heights = [h / np.mean(cy5_data) * 100 for h in peak_heights]\n","\n","                    results_summary.append({\n","                        'Sheet': sheet_name,\n","                        'Rows': f\"{cy5_row}-{cy3_row}\",\n","                        'Cy5 Peaks': len(cy5_peaks),\n","                        'Cy5 Peak Positions': peak_positions,\n","                        'Cy5 Peak Heights': [f\"{h:.2f}\" for h in peak_heights],\n","                        'Cy5 Prominences': [f\"{p:.2f}\" for p in peak_prominences],\n","                        'Cy5 Relative Heights (%)': [f\"{h:.2f}%\" for h in relative_heights],\n","                        'Plot': plot_filename\n","                    })\n","\n","            # Move to the next pair of rows\n","            row += 2\n","\n","        print(f\"Processed {processed_groups} groups, {valid_groups} had Cy5 peaks and no Cy3 peaks in this sheet\")\n","\n","    # Create summary report\n","    if results_summary:\n","        summary_df = pd.DataFrame(results_summary)\n","        summary_df.to_csv(f\"{output_dir}/peak_detection_summary.csv\", index=False)\n","        print(f\"\\nSummary report saved to {output_dir}/peak_detection_summary.csv\")\n","        print(f\"Found {len(results_summary)} instances where Cy5 has peaks and Cy3 has none\")\n","\n","        print(\"\\nPositive matches found:\")\n","        for i, result in enumerate(results_summary, 1):\n","            print(f\"{i}. Sheet: {result['Sheet']}, Rows: {result['Rows']}\")\n","            print(f\"   Cy5 has {result['Cy5 Peaks']} peaks at positions: {result['Cy5 Peak Positions']}\")\n","            print(f\"   Peak heights: {result['Cy5 Peak Heights']}\")\n","            print(f\"   Peak prominences: {result['Cy5 Prominences']}\")\n","            print(f\"   Relative to mean signal: {result['Cy5 Relative Heights (%)']}\")\n","    else:\n","        print(\"\\nNo matching patterns found in the data (Cy5 with peaks and Cy3 without)\")\n","\n","    # Close the log file and restore stdout\n","    sys.stdout = original_stdout\n","    log_handle.close()\n","\n","    print(f\"Results saved to directory: {output_dir}\")\n","    print(f\"Log file saved to: {log_file}\")\n","\n","    return results_summary\n","\n","# Example usage\n","if __name__ == \"__main__\":\n","    import datetime\n","\n","    file_path = \"example_with_positive_cases_edited.xlsx\"\n","\n","    # Generate timestamp for output directory\n","    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","    output_dir = f\"fluorescence_results_{timestamp}\"\n","\n","    # Process with comprehensive peak detection\n","    results = process_excel_file_comprehensive(\n","        file_path,\n","        output_dir=output_dir,\n","        debug_mode=True,  # Set to True to see detailed analysis\n","        window_size=5,    # Size of window for local maxima detection\n","        min_prominence=0.08  # Minimum peak prominence as fraction of data range\n","    )"],"metadata":{"id":"DXRl4Tab2ezf","collapsed":true},"execution_count":null,"outputs":[]}]}